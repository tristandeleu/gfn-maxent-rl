env:
  # Number of parallel environments
  num_envs: 8

  # Prior over graphs P(G)
  prior: "uniform"
  prior_kwargs: {}

  # Score to compute the log-marginal likelihood log P(D | G)
  score: "zero"
  score_kwargs: {}

replay:
  # Capacity of the replay buffer
  capacity: 100_000

  # Number of iterations with a random policy to prefill the replay buffer
  prefill: 1000

exploration:
  # Minimum value of epsilon-exploration
  min_exploration: 0.1

  # Proportion of training steps for warming up exploration
  warmup_prop: 2

# Path to the artifact for input data in Wandb
artifact: "tristandeleu_mila_01/gfn_maxent_rl/er2-lingauss-d005:v0"

# Learning rate
lr: 1e-5

# Batch size
batch_size: 128

# Number of iterations
num_iterations: 100_000

# Frequency of update for the target network (0 = no target network)
update_target_every: 0

# Random seed
seed: 0

# Frequency for logging
log_every: 50

# Name of the group for Wandb
group_name: "default"

# Algorithm
algorithm:
  _target_: "gfn_maxent_rl.algos.detailed_balance.GFNDetailedBalance"
  network:
    _target_: "hydra.utils.get_method"
    path: "gfn_maxent_rl.envs.dag_gfn.policy.policy_network"
  update_target_every: 0
